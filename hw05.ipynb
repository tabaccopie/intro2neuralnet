{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Домашнее задание 5\n",
    "\n",
    "1.Попробуйте изменить параметры нейронной сети, работающей с датасетом imdb, либо нейронной сети, работающей airline-passengers (она прилагается вместе с датасетом к уроку в виде отдельного скрипта) так, чтобы улучшить её точность. Приложите анализ\n",
    "\n",
    "2.Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия. Можно использовать текст другого произведения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, LSTM, GRU\n",
    "#from tensorflow.keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(max_features, max_len, batch_size):\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='nadam', # в данном случае nadam показал результаты лучше, чем adam и adamax\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=1, \n",
    "              validation_data=(x_test, y_test))\n",
    "  \n",
    "    score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "  \n",
    "    print('Результат при тестировании:', score)\n",
    "    print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "При max_features = 15000:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 245s 2s/step - loss: 0.4888 - accuracy: 0.7659 - val_loss: 0.3421 - val_accuracy: 0.8546\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.3421 - accuracy: 0.8546\n",
      "Результат при тестировании: 0.3420848846435547\n",
      "Тестовая точность: 0.854640007019043\n",
      "\n",
      "При max_features = 17500:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 360s 3s/step - loss: 0.4736 - accuracy: 0.7717 - val_loss: 0.3592 - val_accuracy: 0.8502\n",
      "125/125 [==============================] - 45s 349ms/step - loss: 0.3592 - accuracy: 0.8502\n",
      "Результат при тестировании: 0.35923776030540466\n",
      "Тестовая точность: 0.8501999974250793\n",
      "\n",
      "При max_features = 20000:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 249s 2s/step - loss: 0.5069 - accuracy: 0.7581 - val_loss: 0.3451 - val_accuracy: 0.8468\n",
      "125/125 [==============================] - 56s 450ms/step - loss: 0.3451 - accuracy: 0.8468\n",
      "Результат при тестировании: 0.34506916999816895\n",
      "Тестовая точность: 0.8468000292778015\n",
      "\n",
      "При max_features = 22000:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 389s 3s/step - loss: 0.5008 - accuracy: 0.7362 - val_loss: 0.3431 - val_accuracy: 0.8586\n",
      "125/125 [==============================] - 55s 442ms/step - loss: 0.3431 - accuracy: 0.8586\n",
      "Результат при тестировании: 0.3430933654308319\n",
      "Тестовая точность: 0.8585600256919861\n"
     ]
    }
   ],
   "source": [
    "# сначала зафиксируем max_len и batch_size\n",
    "\n",
    "for max_feat in [15000, 17500, 20000, 22000]:\n",
    "    print(f'\\nПри max_features = {max_feat}:\\n')\n",
    "    model_testing(max_feat, 125, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### по результатам данного эксперимента видно, что при увеличении количества фич точность несущественно снижается, в а в последнем случае даже немного увеличивается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "При max_len = 100:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 83s 647ms/step - loss: 0.4916 - accuracy: 0.7628 - val_loss: 0.3758 - val_accuracy: 0.8396\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.3758 - accuracy: 0.8396\n",
      "Результат при тестировании: 0.37584468722343445\n",
      "Тестовая точность: 0.8396400213241577\n",
      "\n",
      "При max_len = 125:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 384s 3s/step - loss: 0.4849 - accuracy: 0.7735 - val_loss: 0.3375 - val_accuracy: 0.8534\n",
      "125/125 [==============================] - 66s 534ms/step - loss: 0.3375 - accuracy: 0.8534\n",
      "Результат при тестировании: 0.3375228941440582\n",
      "Тестовая точность: 0.8533999919891357\n",
      "\n",
      "При max_len = 150:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 423s 3s/step - loss: 0.5350 - accuracy: 0.7225 - val_loss: 0.3482 - val_accuracy: 0.8503\n",
      "125/125 [==============================] - 59s 472ms/step - loss: 0.3482 - accuracy: 0.8503\n",
      "Результат при тестировании: 0.3481884300708771\n",
      "Тестовая точность: 0.8502799868583679\n",
      "\n",
      "При max_len = 175:\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 350s 3s/step - loss: 0.5426 - accuracy: 0.7255 - val_loss: 0.4646 - val_accuracy: 0.8285\n",
      "125/125 [==============================] - 65s 517ms/step - loss: 0.4646 - accuracy: 0.8285\n",
      "Результат при тестировании: 0.4645947217941284\n",
      "Тестовая точность: 0.8285199999809265\n"
     ]
    }
   ],
   "source": [
    "# зафиксируем max_features и batch_size\n",
    "\n",
    "for max_l in  [100, 125, 150, 175]:\n",
    "    print(f'\\nПри max_len = {max_l}:\\n')\n",
    "    model_testing(15000, max_l, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наилучшее значение при max_len = 125, далее точность снижается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "При batch_size = 150: \n",
      "\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "167/167 [==============================] - 879s 5s/step - loss: 0.5051 - accuracy: 0.7373 - val_loss: 0.3380 - val_accuracy: 0.8561\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 0.3380 - accuracy: 0.8561\n",
      "Результат при тестировании: 0.3380450904369354\n",
      "Тестовая точность: 0.8561199903488159\n",
      "\n",
      "При batch_size = 175: \n",
      "\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "143/143 [==============================] - 759s 5s/step - loss: 0.4785 - accuracy: 0.7709 - val_loss: 0.3298 - val_accuracy: 0.8585\n",
      "143/143 [==============================] - 21s 147ms/step - loss: 0.3298 - accuracy: 0.8585\n",
      "Результат при тестировании: 0.32977473735809326\n",
      "Тестовая точность: 0.8584799766540527\n",
      "\n",
      "При batch_size = 200: \n",
      "\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "125/125 [==============================] - 323s 3s/step - loss: 0.5059 - accuracy: 0.7493 - val_loss: 0.3451 - val_accuracy: 0.8504\n",
      "125/125 [==============================] - 70s 558ms/step - loss: 0.3451 - accuracy: 0.8504\n",
      "Результат при тестировании: 0.3450532555580139\n",
      "Тестовая точность: 0.8504400253295898\n",
      "\n",
      "При batch_size = 250: \n",
      "\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.5121 - accuracy: 0.7506 - val_loss: 0.3671 - val_accuracy: 0.8436\n",
      "100/100 [==============================] - 36s 362ms/step - loss: 0.3671 - accuracy: 0.8436\n",
      "Результат при тестировании: 0.3670826852321625\n",
      "Тестовая точность: 0.843559980392456\n"
     ]
    }
   ],
   "source": [
    "# зафиксируем max_features и max_len\n",
    "\n",
    "for batch_s in [150, 175, 200, 250]:\n",
    "    print(f'\\nПри batch_size = {batch_s}:', '\\n', )\n",
    "    model_testing(15000, 125, batch_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Увеличение batch_size приводит к росту точности в интервале до 175, далее точность снижается.\n",
    "\n",
    "##### Оптимальные параметры для модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_features = 15000\n",
    "- max_len = 125\n",
    "- batch_size = 175\n",
    "\n",
    "Результат при тестировании: 0.32977473735809326\n",
    "\n",
    "Тестовая точность: 0.8584799766540527"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построчное чтение файла Alice_in_Wonderland\n",
    "\n",
    "with open(\"Alice_in_Wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN, STEP = 20, 1\n",
    "input_chars, label_chars = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "\n",
    "BATCH_SIZE, HIDDEN_SIZE = 1024, 512\n",
    "NUM_ITERATIONS = 10 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 5\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  \n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Итерация #: 0\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 52s 329ms/step - loss: 1.9081\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 51s 325ms/step - loss: 1.7673\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 51s 329ms/step - loss: 1.6515\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 51s 324ms/step - loss: 1.5550\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 53s 338ms/step - loss: 1.4713\n",
      "Генерация из посева: lat upon their faces\n",
      "lat upon their faces in the wonder would to see would to see would to see would to see would to see would to see would t\n",
      "\n",
      "==================================================\n",
      "Итерация #: 1\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 49s 316ms/step - loss: 1.3965\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 51s 327ms/step - loss: 1.3290\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 53s 342ms/step - loss: 1.2662\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 55s 351ms/step - loss: 1.2080\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 52s 331ms/step - loss: 1.1499\n",
      "Генерация из посева: h that! she went on \n",
      "h that! she went on this to so out to the tried and the things as she spoke, and the things as she spoke, and the things\n",
      "\n",
      "==================================================\n",
      "Итерация #: 2\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 50s 317ms/step - loss: 1.0934\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 53s 337ms/step - loss: 1.0371\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 52s 332ms/step - loss: 0.9803\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 52s 335ms/step - loss: 0.9216\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 52s 333ms/step - loss: 0.8625\n",
      "Генерация из посева: know about it, you m\n",
      "know about it, you might just as well say, and then all the terms of this agreement by the pepper in a low our history, \n",
      "\n",
      "==================================================\n",
      "Итерация #: 3\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 53s 339ms/step - loss: 0.8036\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 53s 341ms/step - loss: 0.7439\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 54s 347ms/step - loss: 0.6828\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 55s 354ms/step - loss: 0.6222\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 54s 345ms/step - loss: 0.5633\n",
      "Генерация из посева:  directions, just li\n",
      " directions, just like a treared of being arm in the seating one of the footman in the comforti to alice, said the dormo\n",
      "\n",
      "==================================================\n",
      "Итерация #: 4\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 51s 329ms/step - loss: 0.5047\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 55s 350ms/step - loss: 0.4512\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 52s 335ms/step - loss: 0.3999\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 52s 331ms/step - loss: 0.3519\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 54s 347ms/step - loss: 0.3089\n",
      "Генерация из посева: ter grumbled: you sh\n",
      "ter grumbled: you should have come to the glass. to youll be neverubed in anything bousd for she finds! she found hersel\n",
      "\n",
      "==================================================\n",
      "Итерация #: 5\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 49s 314ms/step - loss: 0.2725\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 53s 342ms/step - loss: 0.2397\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 57s 364ms/step - loss: 0.2110\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 52s 333ms/step - loss: 0.1860\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 48s 305ms/step - loss: 0.1677\n",
      "Генерация из посева: lobster quadrille th\n",
      "lobster quadrille the mock turtle starem. the queen surpenly was in comitively trought the poor clived rather interestin\n",
      "\n",
      "==================================================\n",
      "Итерация #: 6\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 45s 286ms/step - loss: 0.1529\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 53s 342ms/step - loss: 0.1381\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 52s 336ms/step - loss: 0.1290\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 51s 325ms/step - loss: 0.1205\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 51s 329ms/step - loss: 0.1146\n",
      "Генерация из посева: . and certainly ther\n",
      ". and certainly there was a most extraordinary noise going on within--a constant howling and sneezing, and every now and\n",
      "\n",
      "==================================================\n",
      "Итерация #: 7\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 49s 315ms/step - loss: 0.1082\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 55s 355ms/step - loss: 0.1033\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 57s 367ms/step - loss: 0.1001\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 53s 339ms/step - loss: 0.0974\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 52s 332ms/step - loss: 0.0943\n",
      "Генерация из посева:  hurry; this paper h\n",
      " hurry; this paper has just begun to remark the waster, a bory and licented with se, shaltwint it was all starch and now\n",
      "\n",
      "==================================================\n",
      "Итерация #: 8\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 51s 326ms/step - loss: 0.0920\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 52s 331ms/step - loss: 0.0905\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 51s 329ms/step - loss: 0.0888\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 52s 334ms/step - loss: 0.0879\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 54s 348ms/step - loss: 0.0848\n",
      "Генерация из посева: ws of the state of m\n",
      "ws of the state of mississippi and groventy mase to say by the bitthe words. she had deeply oner dicks and project guten\n",
      "\n",
      "==================================================\n",
      "Итерация #: 9\n",
      "Epoch 1/5\n",
      "156/156 [==============================] - 50s 317ms/step - loss: 0.0838\n",
      "Epoch 2/5\n",
      "156/156 [==============================] - 51s 326ms/step - loss: 0.0836\n",
      "Epoch 3/5\n",
      "156/156 [==============================] - 54s 345ms/step - loss: 0.0810\n",
      "Epoch 4/5\n",
      "156/156 [==============================] - 52s 334ms/step - loss: 0.0798\n",
      "Epoch 5/5\n",
      "156/156 [==============================] - 54s 349ms/step - loss: 0.0797\n",
      "Генерация из посева:  and was surprised t\n",
      " and was surprised to see that she had put on one of the rabbits little white kid gloves while she was talking. how can \n"
     ]
    }
   ],
   "source": [
    "# Выполнение серий тренировочных и демонстрационных итераций \n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # Для каждой итерации запуск передачи данных в модель \n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Для улучшения обучения увеличил количество итераций. Если увеличить HIDDEN_SIZE -- обучение пройдет быстрее, loss снижается. Увеличение SEQLEN так же увеличит скорость обучения модели, но эпохи становятся длительнее, так как моель обучается на более длинной последовательности.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c87bc8a93ee80b4fdb8bf2f0d6e2e42708066a8d3493891b866dc13be9e00029"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsenv_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
